---
title: "[DynDNNs] Outline: Optimizing Runtime & System Level for Dynamic DNN"
author: zerogod
date: 2025-08-01 11:42 +0900
categories: [Research, DynDNNs]
tags: [research, gemmini, llama.cpp, DynDNNs]
render_with_liquid: false
---
## ***Abstract*** 
This outline presents the high-level research plan for ***accelerating dynamic DNN workloads*** at the runtime and system software levels.

## ***1. Introduction*** 
Dynamic DNNs&mdash;neural networks whose input shapes or structures change at runtime&mdash;pose unique challenges for both hardware and system software.  
To address these, we will use **Gemmini** as the **acceleration tool** and **llama.cpp** as the **execution platform**, integrating and optimizing them for variable-shape inference.


## ***2. Organization***
1. **Gemmini Hardware Analysis (Acceleration Tool)** &mdash; Analysis of the Gemmini accelerator’s microarchitecture and its key components.

2. **llama.cpp Framework Analysis (Execution Platform)** &mdash; Review of the llama.cpp (GGML) inference engine’s architecture and inference pipeline.

3. **Research Progress Updates** &mdash; Summary of ongoing work: porting, profiling, and optimization experiments.
